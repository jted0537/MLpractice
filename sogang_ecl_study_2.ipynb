{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sogang-ecl-study-2의 사본",
      "provenance": [],
      "collapsed_sections": [
        "93oTAlQHF9sF",
        "RJ6c9s2_VZiG"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THyOVrc4wXYW"
      },
      "source": [
        "## ECL 연구프로젝트 스터디 2차\n",
        "### PyTorch Tutorial\n",
        "kaggle Playground Competition - [Aerial Cactus Identification](https://https://www.kaggle.com/c/aerial-cactus-identification)</br>\n",
        "PyTorch를 이용해 간단한 Image Classification 문제를 해결해봅시다~!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV6rhhJf1X4K"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.utils.data as utils\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ekZQfI7ygP-"
      },
      "source": [
        "# 데이터 Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EoJxi4_4wyD"
      },
      "source": [
        "!unzip /content/aerial-cactus-identification.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4wrdxSD5xpU"
      },
      "source": [
        "!unzip /content/train.zip\n",
        "!unzip /content/test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_A2k6Lo5iJa"
      },
      "source": [
        "# train.csv 열기\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz8mfRoLwSu1"
      },
      "source": [
        "## Sample Image 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxjdvuZN5rZZ"
      },
      "source": [
        "# image 디렉토리 경로 지정\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by0llLgGPUUx"
      },
      "source": [
        "# sample image 5개 출력\n",
        "sample_path = random.sample(os.listdir(train_dir), 5)\n",
        "\n",
        "fig, axs = plt.subplots(1, 5)\n",
        "fig.set_size_inches(7, 15)\n",
        "for i, path in enumerate(sample_path):\n",
        "    sample = mpimg.imread(os.path.join(train_dir, path))\n",
        "    axs[i].imshow(sample)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIhRVmpBvR1Z"
      },
      "source": [
        "## Custom Dataset를 생성하고, DataLoader로 데이터 불러오기\n",
        "![](https://blog.kakaocdn.net/dn/b0SVvH/btqLq2FmuEs/1hnCz8VL9wvXPKTOTXzvOk/img.jpg)</br></br>\n",
        "PyTorch로 데이터를 불러오기 위해서는 custom Dataset class를 생성하고, DataLoader로 dataset class를 불러와야한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJTduJ991_14"
      },
      "source": [
        "<dl class=\"class\">\n",
        "<dt id=\"torch.utils.data.Dataset\">\n",
        "<em class=\"property\">class </em><code class=\"sig-prename descclassname\">torch.utils.data.</code><code class=\"sig-name descname\">Dataset</code></dt>\n",
        "<dd><p>An abstract class representing a <a class=\"reference internal\" href=\"#torch.utils.data.Dataset\" title=\"torch.utils.data.Dataset\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Dataset</span></code></a>.</p>\n",
        "<p>All datasets that represent a map from keys to data samples should subclass\n",
        "it. All subclasses should overwrite <code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">__getitem__()</span></code>, supporting fetching a\n",
        "data sample for a given key. Subclasses could also optionally overwrite\n",
        "<code class=\"xref py py-meth docutils literal notranslate\"><span class=\"pre\">__len__()</span></code>, which is expected to return the size of the dataset by many\n",
        "<a class=\"reference internal\" href=\"#torch.utils.data.Sampler\" title=\"torch.utils.data.Sampler\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Sampler</span></code></a> implementations and the default options\n",
        "of <a class=\"reference internal\" href=\"#torch.utils.data.DataLoader\" title=\"torch.utils.data.DataLoader\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\"><span class=\"highlighted\">DataLoader</span></span></code></a>.</p>\n",
        "<div class=\"admonition note\">\n",
        "<p class=\"admonition-title\">Note</p>\n",
        "<p><a class=\"reference internal\" href=\"#torch.utils.data.DataLoader\" title=\"torch.utils.data.DataLoader\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\"><span class=\"highlighted\">DataLoader</span></span></code></a> by default constructs a index\n",
        "sampler that yields integral indices.  To make it work with a map-style\n",
        "dataset with non-integral indices/keys, a custom sampler must be provided.</p>\n",
        "</div>\n",
        "</dd></dl>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3FAszjM1pPX"
      },
      "source": [
        "<pre><span></span><span class=\"n\"><span class=\"highlighted\">DataLoader</span></span><span class=\"p\">(</span><span class=\"n\">dataset</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">shuffle</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">sampler</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n",
        "           <span class=\"n\">batch_sampler</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">num_workers</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"n\">collate_fn</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span>\n",
        "           <span class=\"n\">pin_memory</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">drop_last</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">,</span> <span class=\"n\">timeout</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">,</span>\n",
        "           <span class=\"n\">worker_init_fn</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"p\">,</span> <span class=\"n\">prefetch_factor</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">,</span>\n",
        "           <span class=\"n\">persistent_workers</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fGaF8RZDZK5"
      },
      "source": [
        "# custom Dataset 만들기\n",
        "\n",
        "\n",
        "    # 데이터셋 크기 return\n",
        "\n",
        "\n",
        "    # 주어진 index에 해당하는 데이터 return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQhf93aC6N5G"
      },
      "source": [
        "# train, validation 데이터 split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCrpUJOzNxZp"
      },
      "source": [
        "# data transform 정의\n",
        "data_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                     transforms.ToTensor()])\n",
        "\n",
        "\n",
        "# Dataset 객체 생성 후, DataLoader로 tensor형식 데이터 iterator 불러오기\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymez8dWQVkvp"
      },
      "source": [
        "# Model 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCS5EorAbdXR"
      },
      "source": [
        "<dt id=\"torch.nn.Conv2d\">\n",
        "<em class=\"property\">class </em><code class=\"sig-prename descclassname\">torch.nn.</code><code class=\"sig-name descname\">Conv2d</code><span class=\"sig-paren\">(</span><em class=\"sig-param\">in_channels</em>, <em class=\"sig-param\">out_channels</em>, <em class=\"sig-param\">kernel_size</em>, <em class=\"sig-param\">stride=1</em>, <em class=\"sig-param\">padding=0</em>, <em class=\"sig-param\">dilation=1</em>, <em class=\"sig-param\">groups=1</em>, <em class=\"sig-param\">bias=True</em>, <em class=\"sig-param\">padding_mode='zeros'</em><span class=\"sig-paren\">)</span></a></dt>\n",
        "\n",
        "<ul>\n",
        "<li><p><code class=\"xref py py-attr docutils literal notranslate\"><span class=\"pre\">stride</span></code> controls the stride for the cross-correlation, a single\n",
        "number or a tuple.</p></li>\n",
        "<li><p><code class=\"xref py py-attr docutils literal notranslate\"><span class=\"pre\">padding</span></code> controls the amount of implicit padding on both\n",
        "sides for <code class=\"xref py py-attr docutils literal notranslate\"><span class=\"pre\">padding</span></code> number of points for each dimension.</p></li>\n",
        "<li><p><code class=\"xref py py-attr docutils literal notranslate\"><span class=\"pre\">dilation</span></code> controls the spacing between the kernel points; also\n",
        "known as the à trous algorithm. It is harder to describe, but this <a class=\"reference external\" href=\"https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\">link</a>\n",
        "has a nice visualization of what <code class=\"xref py py-attr docutils literal notranslate\"><span class=\"pre\">dilation</span></code> does.</p></li>\n",
        "<li><p><code class=\"xref py py-attr docutils literal notranslate\"><span class=\"pre\">groups</span></code> controls the connections between inputs and outputs.\n",
        "<code class=\"xref py py-attr docutils literal notranslate\"><span class=\"pre\">in_channels</span></code> and <code class=\"xref py py-attr docutils literal notranslate\"><span class=\"pre\">out_channels</span></code> must both be divisible by\n",
        "<code class=\"xref py py-attr docutils literal notranslate\"><span class=\"pre\">groups</span></code>. For example,</p>\n",
        "<blockquote>\n",
        "<div><ul class=\"simple\">\n",
        "<li><p>At groups=1, all inputs are convolved to all outputs.</p></li>\n",
        "<li><p>At groups=2, the operation becomes equivalent to having two conv\n",
        "layers side by side, each seeing half the input channels\n",
        "and producing half the output channels, and both subsequently\n",
        "concatenated.</p></li>\n",
        "<li><p>At groups= <code class=\"xref py py-attr docutils literal notranslate\"><span class=\"pre\">in_channels</span></code>, each input channel is convolved with\n",
        "its own set of filters (of size\n",
        "<span class=\"math\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mtext>out_channels</mtext><mtext>in_channels</mtext></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.5751079999999997em;vertical-align:-0.5619999999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.013108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">in_channels</span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.527em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">out_channels</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5619999999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>\n",
        "\n",
        "</span>).</p></li>\n",
        "</ul>\n",
        "</div></blockquote>\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oKlmFm0yqiV"
      },
      "source": [
        "## 간단한 모델구조 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfHTECyyzNvD"
      },
      "source": [
        "# nn.Module 클래스를 상속받아 나만의 모델 정의\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krXTL8ay4LLG"
      },
      "source": [
        "# 모델 생성 후 모델정보 출력\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqWeNvqa8EK8"
      },
      "source": [
        "## Conv2d Shape</br>\n",
        "$$ Input: (N, C_{in}, H_{in}, W_{in}) $$\n",
        "$$ Output: (N, C_{out}, H_{out}, W_{out}) $$\n",
        "\n",
        "$${H_{out}}=⌊\\frac{H_{in}+2×padding[0]−dilation[0]×(kernelsize[0]−1)−1}{stride[0]}+1⌋$$\n",
        "\n",
        "$$W_{out}=⌊\\frac{{W_{in}}+2×padding[1]−dilation[1]×(kernelsize[1]−1)−1}{stride[1]}+1⌋ $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrUcR04C4bT6"
      },
      "source": [
        "# 데이터를 모델에 넣으면 결과가 어떻게 나오는지 한번 봅시다!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzJ-nB7su40c"
      },
      "source": [
        "## 복잡한 모델 만들기\n",
        "![](https://krshrimali.github.io/assets/ResNet18-Architecture.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93oTAlQHF9sF"
      },
      "source": [
        "## BasicBlock"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFezmA02MIgi"
      },
      "source": [
        "![](https://i.imgur.com/Aj8dDLj.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr-8oqMv3KOu"
      },
      "source": [
        "def conv3x3(in_channels, out_channels, stride=1, dilation=1) -> nn.Conv2d:\n",
        "  return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n",
        "                   padding=dilation, bias=False, dilation=dilation)\n",
        "  \n",
        "def conv1x1(in_channels, out_channels, stride=1) -> nn.Conv2d:\n",
        "  return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "  \n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion: int = 1\n",
        "\n",
        "    def __init__(self, in_channels: int, channels: int, stride: int = 1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "                \n",
        "        # actual layers\n",
        "        self.conv1 = conv3x3(in_channels, channels, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(channels, channels)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "        self.stride = stride\n",
        "        self.downsample = nn.Sequential(\n",
        "                conv1x1(in_channels, channels, stride),\n",
        "                nn.BatchNorm2d(channels),\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        \n",
        "        out += self.downsample(identity)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ6c9s2_VZiG"
      },
      "source": [
        "## Bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE3KvUAur5_d"
      },
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    expansion: int = 4\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        channels,\n",
        "        stride,\n",
        "        downsample: Optional[nn.Module] = None,\n",
        "        groups: int=1,\n",
        "        base_width:int = 64,\n",
        "        dilation: int=1,\n",
        "        norm_layer:Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(channels * (base_width / 64.)) * groups\n",
        "        \n",
        "        # actual layer\n",
        "        self.conv1 = conv1x1(in_channels, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, channels*self.expansion)\n",
        "        self.bn3 = norm_layer(channels*self.expansion)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        \n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FPp7NulVd-p"
      },
      "source": [
        "## Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmcQ69Q2s-vG"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers: List[int],):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.norm_layer = nn.BatchNorm2d\n",
        "\n",
        "        self.in_channels = 64\n",
        "        self.dilation = 1\n",
        "\n",
        "        self.conv1 = \n",
        "        self.bn1 = \n",
        "        self.relu = \n",
        "        self.maxpool = \n",
        "        self.layer1 = \n",
        "        self.layer2 = \n",
        "        self.layer3 = \n",
        "        \n",
        "        self.avgpool = \n",
        "        self.sigmoid = \n",
        "        self.fc = \n",
        "\n",
        "        # weight/bias initialize\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "    \n",
        "    # 블록을 쌓아주는 함수\n",
        "    def _make_layer(self, block, channels, block_num, stride: int=1) -> nn.Sequential:\n",
        "        \n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, channels, stride))\n",
        "        self.in_channels = channels * block.expansion\n",
        "        for _ in range(1, block_num):\n",
        "            layers.append(block(self.in_channels, channels, stride))\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr6FxMNf3KJs"
      },
      "source": [
        "resnet = ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "print(resnet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzMkqT6yVhmV"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR9iV3qg5_4b"
      },
      "source": [
        "# optimizer, loss function 정의\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnUAM0w1Apiv"
      },
      "source": [
        "def accuracy(pred, target):\n",
        "    y_pred_tag = torch.round(pred)\n",
        "    correct_sum = (y_pred_tag == target).sum().item()\n",
        "    acc = correct_sum / target.shape[0]\n",
        "\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbAA6gf3INJU"
      },
      "source": [
        "![](https://pytorch.org/tutorials/_images/comp-graph.png)\n",
        "\n",
        "파이토치의 gradient는 x가 network를 통과하면서 자동으로 계산된다(autograd)</br>\n",
        "graident의 미분값은 **loss.backward()**를 호출해 계산하고,</br>\n",
        "**optimizer.step()**을 호출해 parameter(weight, bias)들을 update한다.</br>\n",
        "따라서 training 동안은 위 함수들을 호출하지만, evaluation 동안은 gradient가 적용되지 않아야 하므로,</br> **torch.no_grad()**로 network 진행동안 graident가 기록되지 않도록 한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anigdODD5uYo"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# 모델 훈련 코드 작성\n",
        "def train(model, epoch, dataloader, optimizer, loss_function):\n",
        "    model.train()\n",
        "    loss_log = []\n",
        "    acc_log = []\n",
        "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
        "        for data, target in tepoch:\n",
        "\n",
        "\n",
        "            # optimizer gradient 초기화\n",
        "\n",
        "\n",
        "            # model에 데이터 넣은 결과 생성\n",
        "\n",
        "\n",
        "            # grad 미분값 계산 후 모델 update\n",
        "\n",
        "            \n",
        "            # accuracy & loss 저장 후 출력\n",
        "            acc = accuracy(output, target.unsqueeze(1))\n",
        "            loss_log.append(loss.item())\n",
        "            acc_log.append(acc)\n",
        "            tepoch.set_postfix(epoch=epoch, step=\"train\", loss=np.mean(loss_log), accuracy=np.mean(acc_log))\n",
        "\n",
        "# 모델 평가 코드 작성\n",
        "def eval(model, epoch, dataloader, loss_function):\n",
        "    model.eval()\n",
        "    loss_log = []\n",
        "    acc_log = []\n",
        "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
        "        # no_grad를 호출해 evaluation동안 gradient 계산 X\n",
        "        \n",
        "            for data, target in tepoch:\n",
        "                \n",
        "                \n",
        "                # accuracy & loss 저장 후 출력\n",
        "                loss_log.append(loss.item())\n",
        "                acc = accuracy(output, target.unsqueeze(1))\n",
        "                acc_log.append(acc)\n",
        "                tepoch.set_postfix(epoch=epoch, step=\"eval\", loss=np.mean(loss_log), accuracy=np.mean(acc_log))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFcEJJefSnCn"
      },
      "source": [
        "# Train Model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6iprRDSZAsI"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YRjClAaY3re"
      },
      "source": [
        "submit = pd.read_csv('/content/sample_submission.csv')\n",
        "test_data = CactusData(df = submit, data_dir = test_dir, transform = data_transform)\n",
        "test_loader = DataLoader(dataset = test_data, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFCHon_OZAOJ"
      },
      "source": [
        "%%time\n",
        "predict = []\n",
        "resnet.eval()\n",
        "with torch.no_grad():\n",
        "    for i, (data, _) in enumerate(test_loader):\n",
        "        data = data.cuda()\n",
        "        output = resnet(data)    \n",
        "\n",
        "        predict.append(int(output.item() > 0.5))\n",
        "    \n",
        "submit['has_cactus'] = predict\n",
        "submit.to_csv('/content/submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUHCgBhPZNPm"
      },
      "source": [
        "submit.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}